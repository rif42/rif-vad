<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Decibel Meter</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }

        #decibelDisplay {
            font-size: 48px;
            font-weight: bold;
            margin: 20px;
            padding: 20px;
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .controls {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
        }

        button:hover {
            background-color: #45a049;
        }

        #features {
            display: flex;
            gap: 20px;
            margin: 20px;
            padding: 20px;
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .feature {
            text-align: center;
        }

        .feature-value {
            font-size: 24px;
            font-weight: bold;
        }
    </style>
</head>

<body>
    <h1>Voice Decibel Meter</h1>
    <div class="controls">
        <button id="toggleBtn">Start Recording</button>
    </div>
    <div id="decibelDisplay">0 dB</div>

    <div id="features">
        <div class="feature">
            <div>Energy (dB)</div>
            <div id="energyValue" class="feature-value">0</div>
        </div>
        <div class="feature">
            <div>ZCR</div>
            <div id="zcrValue" class="feature-value">0</div>
        </div>
        <div class="feature">
            <div>Spectral Centroid</div>
            <div id="centroidValue" class="feature-value">0</div>
        </div>
    </div>

    <div id="features">
        <div class="feature">
            <div>Noise Floor Threshold</div>
            <div id="noiseFloorThresholdValue" class="feature-value">0</div>
        </div>
        <div class="feature">
            <div>ZCR Threshold</div>
            <div id="zcrThresholdValue" class="feature-value">0</div>
        </div>
        <div class="feature">
            <div>Spectral Centroid Threshold</div>
            <div id="centroidThresholdValue" class="feature-value">0</div>
        </div>
    </div>

    <div id="features">
        <div class="feature">
            <div>System Status</div>
            <div id="calibrationStatus" class="feature-value">Calibrating</div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let stream;
        let isRecording = false;
        let animationId;

        // Configuration parameters
        const CONFIG = {
            // How many previous frames to consider for adaptation
            frameMemory: 200,

            // FFT size affects frequency resolution
            fftSize: 256,

            // Thresholding factors
            energyThresholdFactor: 0.7, // Higher = less sensitive to energy
            zcrThresholdFactor: 1.4, // Higher = less sensitive to ZCR
            centroidThresholdFactor: 1.15, // Higher = less sensitive to centroid

            // Noise floor settings
            noiseFloorPercentile: 15, // Percentile to use for noise floor (10th percentile)
            noiseFloorOffset: 8, // dB above noise floor to consider as minimum

            // Minimum values to consider as speech
            minCentroid: 1000, // Minimum spectral centroid

            // Smoothing
            smoothingTimeConstant: 0.8, // 0-1, higher = more smoothing  

            // Voice detection stability settings
            holdTimeMs: 800, // How long to hold "active" state after voice detected
            minVoiceMs: 200, // Minimum time voice must be detected to trigger
            hysteresisFactor: 0.35, // Additional threshold reduction once voice is active

            // specific multipliers
            unvoicedZcrMultiplier: 1.4,
            unvoicedCentroidMultiplier: 1.25,
            voicedZcrMultiplier: 0.65,

            initialCalibrationTime: 3000, // 3 seconds of silent calibration
            initialNoiseFloor: -60,      // Conservative starting point
            initialZCR: 0.2,             // Typical noise ZCR
            initialCentroid: 800         // Typical noise centroid
        };

        // Buffer for adaptive thresholding
        let energyHistory = new Array(CONFIG.frameMemory).fill(CONFIG.initialNoiseFloor);
        let zcrHistory = new Array(CONFIG.frameMemory).fill(CONFIG.initialZCR);
        let centroidHistory = new Array(CONFIG.frameMemory).fill(CONFIG.initialCentroid);

        // Add state tracking variables
        let lastVoiceDetectedTime = 0;
        let voiceHoldTimer = null;
        let isVoiceHeld = false;
        let consecutiveVoiceTime = 0;
        let lastFrameTime = 0;

        // Add calibration state tracking
        let calibrationStartTime = 0;
        let isCalibrating = false;

        const toggleBtn = document.getElementById('toggleBtn');
        let audioContext = null;

        toggleBtn.addEventListener('click', async () => {
            if (!isRecording) {
                try {
                    stream = await navigator.mediaDevices.getUserMedia({
                        audio: true,
                        noiseSuppression: true,
                        echoCancellation: true,
                        autoGainControl: true
                    });

                    // Voice recording variables
                    let voiceRecorder = null;
                    let voiceChunks = [];
                    let wasVoiceActive = false;

                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    const analyzer = audioContext.createAnalyser();
                    analyzer.fftSize = CONFIG.fftSize;
                    analyzer.smoothingTimeConstant = CONFIG.smoothingTimeConstant;
                    source.connect(analyzer);

                    voiceRecorder = new MediaRecorder(stream);

                    function calculateZCR(timeData) {
                        let crossings = 0;
                        for (let i = 1; i < timeData.length; i++) {
                            if ((timeData[i] >= 0 && timeData[i - 1] < 0) ||
                                (timeData[i] < 0 && timeData[i - 1] >= 0)) {
                                crossings++;
                            }
                        }
                        return crossings / timeData.length;
                    }

                    function calculateSpectralCentroid(frequencyData, sampleRate) {
                        let numerator = 0;
                        let denominator = 0;

                        for (let i = 0; i < frequencyData.length; i++) {
                            const frequency = (i * sampleRate) / (frequencyData.length * 2);
                            numerator += frequency * frequencyData[i];
                            denominator += frequencyData[i];
                        }

                        return denominator === 0 ? 0 : numerator / denominator;
                    }

                    function calculateNoiseFloor(energyHistory) {
                        // Sort a copy of the energy history
                        const sortedEnergies = [...energyHistory].sort((a, b) => a - b);

                        // Calculate the index for the percentile
                        const index = Math.floor((CONFIG.noiseFloorPercentile / 100) * sortedEnergies.length);

                        // Get the noise floor and add the offset
                        return sortedEnergies[index] + CONFIG.noiseFloorOffset;
                    }

                    function updateAdaptiveThresholds() {
                        const energyMean = energyHistory.reduce((a, b) => a + b) / CONFIG.frameMemory;
                        const energyStd = Math.sqrt(
                            energyHistory.reduce((a, b) => a + Math.pow(b - energyMean, 2), 0) / CONFIG.frameMemory
                        );

                        const zcrMean = zcrHistory.reduce((a, b) => a + b) / CONFIG.frameMemory;
                        const centroidMean = centroidHistory.reduce((a, b) => a + b) / CONFIG.frameMemory;

                        // Calculate adaptive noise floor
                        const noiseFloor = calculateNoiseFloor(energyHistory).toFixed(3);
                        const zcrThreshold = (zcrMean * CONFIG.zcrThresholdFactor).toFixed(3);
                        const centroidThreshold = Math.max(
                            centroidMean * CONFIG.centroidThresholdFactor,
                            CONFIG.minCentroid
                        ).toFixed(3);

                        document.getElementById('noiseFloorThresholdValue').textContent = noiseFloor;
                        document.getElementById('zcrThresholdValue').textContent = zcrThreshold;
                        document.getElementById('centroidThresholdValue').textContent = centroidThreshold;

                        return {
                            energyThreshold: Math.max(
                                energyMean - (energyStd * CONFIG.energyThresholdFactor),
                                noiseFloor  // Use noise floor instead of fixed minEnergy
                            ),
                            zcrThreshold: zcrMean * CONFIG.zcrThresholdFactor,
                            centroidThreshold: Math.max(
                                centroidMean * CONFIG.centroidThresholdFactor,
                                CONFIG.minCentroid
                            ),
                            noiseFloor  // Include noise floor in return values
                        };
                    }

                    function updateDecibels() {
                        if (!isCalibrating) {
                            calibrationStartTime = Date.now();
                            isCalibrating = true;
                        }

                        const currentTime = Date.now();
                        const deltaTime = lastFrameTime ? currentTime - lastFrameTime : 0;
                        lastFrameTime = currentTime;

                        const bufferLength = analyzer.frequencyBinCount;
                        const timeData = new Float32Array(bufferLength);
                        const frequencyData = new Uint8Array(bufferLength);

                        analyzer.getFloatTimeDomainData(timeData);
                        analyzer.getByteFrequencyData(frequencyData);

                        // Calculate RMS and convert to decibels
                        const rms = Math.sqrt(
                            timeData.reduce((sum, value) => sum + (value * value), 0) / bufferLength
                        );
                        const decibels = 20 * Math.log10(rms || 0.0000001);

                        // Calculate ZCR
                        const zcr = calculateZCR(timeData);

                        // Calculate Spectral Centroid
                        const centroid = calculateSpectralCentroid(frequencyData, audioContext.sampleRate);

                        // Update histories
                        energyHistory = [...energyHistory.slice(1), decibels];
                        zcrHistory = [...zcrHistory.slice(1), zcr];
                        centroidHistory = [...centroidHistory.slice(1), centroid];

                        // Get adaptive thresholds
                        const thresholds = updateAdaptiveThresholds();

                        // Apply hysteresis when voice is held
                        const activeEnergyThreshold = isVoiceHeld ?
                            thresholds.energyThreshold - (CONFIG.hysteresisFactor * Math.abs(thresholds.energyThreshold)) :
                            thresholds.energyThreshold;

                        // Modify voice detection logic
                        const instantVoiceActive = (
                            (Date.now() - calibrationStartTime > CONFIG.initialCalibrationTime) && // Block during calibration
                            (zcr < thresholds.zcrThreshold * CONFIG.voicedZcrMultiplier &&
                                centroid > thresholds.centroidThreshold) ||
                            (zcr > thresholds.zcrThreshold * CONFIG.unvoicedZcrMultiplier &&
                                centroid > thresholds.centroidThreshold * CONFIG.unvoicedCentroidMultiplier)
                        ) && decibels > thresholds.noiseFloor;

                        // Update consecutive voice time
                        if (instantVoiceActive) {
                            consecutiveVoiceTime += deltaTime;
                            lastVoiceDetectedTime = currentTime;

                            // If we exceed minimum voice time, start/extend hold timer
                            if (consecutiveVoiceTime >= CONFIG.minVoiceMs) {
                                if (voiceHoldTimer) {
                                    clearTimeout(voiceHoldTimer);
                                }
                                voiceHoldTimer = setTimeout(() => {
                                    isVoiceHeld = false;
                                    consecutiveVoiceTime = 0;
                                }, CONFIG.holdTimeMs);
                                isVoiceHeld = true;
                            }
                        } else {
                            // Only reset consecutive time if we're not in hold period
                            if (currentTime - lastVoiceDetectedTime > CONFIG.holdTimeMs) {
                                consecutiveVoiceTime = 0;
                            }
                        }

                        // Final voice active state combines instant detection and hold state
                        const isVoiceActive = isVoiceHeld ||
                            (instantVoiceActive && consecutiveVoiceTime >= CONFIG.minVoiceMs);

                        // Voice-controlled recording logic
                        if (isVoiceActive && !wasVoiceActive) {
                            // Start new recording session
                            voiceChunks = [];
                            voiceRecorder.ondataavailable = e => voiceChunks.push(e.data);
                            voiceRecorder.onstop = () => {
                                const audioBlob = new Blob(voiceChunks, { type: 'audio/webm' });
                                const audioUrl = URL.createObjectURL(audioBlob);
                                const audio = new Audio(audioUrl);
                                audio.play();
                                audio.onended = () => URL.revokeObjectURL(audioUrl);
                            };
                            voiceRecorder.start();
                        } else if (!isVoiceActive && wasVoiceActive) {
                            // Stop current recording session
                            if (voiceRecorder && voiceRecorder.state === 'recording') {
                                voiceRecorder.stop();
                            }
                        }

                        wasVoiceActive = isVoiceActive;

                        // Update displays
                        const displayValue = Math.round(decibels * 10) / 10;
                        const decibelDisplay = document.getElementById('decibelDisplay');
                        decibelDisplay.textContent = `${displayValue} dB`;
                        decibelDisplay.style.backgroundColor = isVoiceActive ? 'green' : 'white';
                        decibelDisplay.style.color = isVoiceActive ? 'white' : 'black';

                        // Update feature displays
                        document.getElementById('energyValue').textContent =
                            `${displayValue} dB`; // Show noise floor
                        document.getElementById('zcrValue').textContent = zcr.toFixed(3);
                        document.getElementById('centroidValue').textContent = Math.round(centroid);

                        // if a feature above threshold, change the color of the feature to green
                        if (decibels > thresholds.energyThreshold) {
                            document.getElementById('energyValue').style.backgroundColor = 'green';
                        } else {
                            document.getElementById('energyValue').style.backgroundColor = 'white';
                        }

                        if (zcr < thresholds.zcrThreshold) {
                            document.getElementById('zcrValue').style.backgroundColor = 'green';
                        } else {
                            document.getElementById('zcrValue').style.backgroundColor = 'white';
                        }

                        if (centroid > thresholds.centroidThreshold) {
                            document.getElementById('centroidValue').style.backgroundColor = 'green';
                        } else {
                            document.getElementById('centroidValue').style.backgroundColor = 'white';
                        }

                        // Add visual feedback
                        document.getElementById('calibrationStatus').textContent =
                            isCalibrating ? `Calibrating (${CONFIG.initialCalibrationTime / 1000}s)` : "Ready";

                        animationId = requestAnimationFrame(updateDecibels);
                    }

                    updateDecibels();
                    toggleBtn.textContent = 'Stop Recording';
                    isRecording = true;
                } catch (err) {
                    console.error('Error accessing microphone:', err);
                }
            } else {
                // Cleanup resources
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
                if (audioContext) {
                    audioContext.close();
                }
                cancelAnimationFrame(animationId);
                toggleBtn.textContent = 'Start Recording';
                isRecording = false;
            }
        });

        // Stop recording button

    </script>
</body>

</html>